1. Customers Table

import pandas as pd

# Load the Customers dataset
customers_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Customers.csv')

# Generate INSERT statements for Customers table
for index, row in customers_df.iterrows():
    print(f"INSERT INTO Customers (customerkey, gender, name, city, state_code, state, zip_code, country, continent, birthday) "
          f"VALUES ({row['customerkey']}, '{row['gender']}', '{row['name']}', '{row['city']}', '{row['state_code']}', "
          f"'{row['state']}', '{row['zip_code']}', '{row['country']}', '{row['continent']}', '{row['birthday']}');")



2. Exchange Rates Table

# Load the Exchange Rates dataset
exchange_rates_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Exchange_Rates.csv')

# Generate INSERT statements for Exchange Rates table
for index, row in exchange_rates_df.iterrows():
    print(f"INSERT INTO Exchange_Rates (date, currency_code, exchange_rate) "
          f"VALUES ('{row['date']}', '{row['currency_code']}', {row['exchange_rate']});")



3. Products Table

# Load the Products dataset
products_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Products.csv')

# Generate INSERT statements for Products table
for index, row in products_df.iterrows():
    print(f"INSERT INTO Products (ProductKey, ProductName, Brand, Color, UnitCostUSD, UnitPriceUSD, SubcategoryKey, Subcategory, CategoryKey, Category) "
          f"VALUES ({row['ProductKey']}, '{row['Product Name']}', '{row['Brand']}', '{row['Color']}', {row['Unit Cost USD']}, {row['Unit Price USD']}, "
          f"{row['SubcategoryKey']}, '{row['Subcategory']}', {row['CategoryKey']}, '{row['Category']}');")



4. Sales Table

import pandas as pd
import numpy as np

# Load the Sales dataset
sales_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Sales.csv')

# Generate INSERT statements for Sales table with ON DUPLICATE KEY UPDATE, and handle NaN as NULL
for index, row in sales_df.iterrows():
    order_number = row['Order Number']
    line_item = row['Line Item']
    order_date = f"'{row['Order Date']}'" if pd.notna(row['Order Date']) else 'NULL'
    delivery_date = f"'{row['Delivery Date']}'" if pd.notna(row['Delivery Date']) else 'NULL'
    customerkey = row['CustomerKey'] if pd.notna(row['CustomerKey']) else 'NULL'
    storekey = row['StoreKey'] if pd.notna(row['StoreKey']) else 'NULL'
    productkey = row['ProductKey'] if pd.notna(row['ProductKey']) else 'NULL'
    quantity = row['Quantity'] if pd.notna(row['Quantity']) else 'NULL'
    currency_code = f"'{row['Currency Code']}'" if pd.notna(row['Currency Code']) else 'NULL'

    print(f"INSERT INTO Sales (order_number, line_item, order_date, delivery_date, customerkey, storekey, productkey, quantity, currency_code) "
          f"VALUES ({order_number}, {line_item}, {order_date}, {delivery_date}, {customerkey}, {storekey}, {productkey}, {quantity}, {currency_code}) "
          f"ON DUPLICATE KEY UPDATE "
          f"order_date = VALUES(order_date), delivery_date = VALUES(delivery_date), customerkey = VALUES(customerkey), "
          f"storekey = VALUES(storekey), productkey = VALUES(productkey), quantity = VALUES(quantity), currency_code = VALUES(currency_code);")


5. Stores Table

import pandas as pd

# Load the Stores dataset
stores_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Stores.csv')

# Generate INSERT statements for Stores table with corrected date format and handle duplicates
for index, row in stores_df.iterrows():
    print(f"INSERT INTO Stores (storekey, country, state, square_meters, open_date) "
          f"VALUES ({row['StoreKey']}, '{row['Country']}', '{row['State']}', {row['Square Meters']}, '{row['Open Date']}') "
          f"ON DUPLICATE KEY UPDATE "
          f"country = VALUES(country), state = VALUES(state), square_meters = VALUES(square_meters), open_date = VALUES(open_date);")





6. Merged Table

# Load the Final Merged dataset
merged_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Final_Merged.csv')

# Replace NaN values with None, which corresponds to SQL NULL
merged_df = merged_df.replace({np.nan: None})

# Generate SQL INSERT statements
for index, row in merged_df.iterrows():
    order_number = row['Order Number'] if row['Order Number'] is not None else 'NULL'
    line_item = row['Line Item'] if row['Line Item'] is not None else 'NULL'
    order_date = f"'{row['Order Date']}'" if row['Order Date'] is not None else 'NULL'
    delivery_date = f"'{row['Delivery Date']}'" if row['Delivery Date'] is not None else 'NULL'
    customerkey = row['CustomerKey'] if row['CustomerKey'] is not None else 'NULL'
    storekey = row['StoreKey'] if row['StoreKey'] is not None else 'NULL'
    productkey = row['ProductKey'] if row['ProductKey'] is not None else 'NULL'
    quantity = row['Quantity'] if row['Quantity'] is not None else 'NULL'
    currency_code = f"'{row['Currency Code']}'" if row['Currency Code'] is not None else 'NULL'

    customer_name = f"'{row['name']}'" if row['name'] is not None else 'NULL'
    city = f"'{row['city']}'" if row['city'] is not None else 'NULL'
    state_code = f"'{row['state_code']}'" if row['state_code'] is not None else 'NULL'
    state = f"'{row['state']}'" if row['state'] is not None else 'NULL'
    zip_code = f"'{row['zip_code']}'" if row['zip_code'] is not None else 'NULL'
    country = f"'{row['country']}'" if row['country'] is not None else 'NULL'
    continent = f"'{row['continent']}'" if row['continent'] is not None else 'NULL'
    birthday = f"'{row['birthday']}'" if row['birthday'] is not None else 'NULL'
    product_name = f"'{row['Product Name']}'" if row['Product Name'] is not None else 'NULL'
    brand = f"'{row['Brand']}'" if row['Brand'] is not None else 'NULL'
    color = f"'{row['Color']}'" if row['Color'] is not None else 'NULL'
    unit_cost_usd = row['Unit Cost USD'] if row['Unit Cost USD'] is not None else 'NULL'
    unit_price_usd = row['Unit Price USD'] if row['Unit Price USD'] is not None else 'NULL'
    subcategory_key = row['SubcategoryKey'] if row['SubcategoryKey'] is not None else 'NULL'
    subcategory = f"'{row['Subcategory']}'" if row['Subcategory'] is not None else 'NULL'
    category_key = row['CategoryKey'] if row['CategoryKey'] is not None else 'NULL'
    category = f"'{row['Category']}'" if row['Category'] is not None else 'NULL'
    
    # Columns renamed to match the table structure
    store_square_meters = row['Square Meters'] if row['Square Meters'] is not None else 'NULL'
    store_open_date = f"'{row['Open Date']}'" if row['Open Date'] is not None else 'NULL'
    currency = f"'{row['currency']}'" if row['currency'] is not None else 'NULL'
    exchange_rate = row['exchange'] if row['exchange'] is not None else 'NULL'
    
    # Missing columns added
    store_country = f"'{row['Country']}'" if row['Country'] is not None else 'NULL'
    store_state = f"'{row['State']}'" if row['State'] is not None else 'NULL'
    exchange_date = f"'{row['date']}'" if row['date'] is not None else 'NULL'

    # Generate the SQL query
    print(
        f"INSERT INTO merged_dataset (order_number, line_item, order_date, delivery_date, customer_key, store_key, product_key, quantity, currency_code, "
        f"customer_name, city, state_code, state, zip_code, country, continent, birthday, product_name, brand, color, "
        f"unit_cost_usd, unit_price_usd, subcategory_key, subcategory, category_key, category, store_square_meters, store_open_date, "
        f"store_country, store_state, exchange_date, currency, exchange_rate) "
        f"VALUES ({order_number}, {line_item}, {order_date}, {delivery_date}, {customerkey}, {storekey}, {productkey}, {quantity}, {currency_code}, "
        f"{customer_name}, {city}, {state_code}, {state}, {zip_code}, {country}, {continent}, {birthday}, {product_name}, "
        f"{brand}, {color}, {unit_cost_usd}, {unit_price_usd}, {subcategory_key}, {subcategory}, {category_key}, {category}, {store_square_meters}, "
        f"{store_open_date}, {store_country}, {store_state}, {exchange_date}, {currency}, {exchange_rate});")
