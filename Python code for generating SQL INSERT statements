1. Customers Table

import pandas as pd

# Load the Customers dataset
customers_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Customers.csv')

# Generate INSERT statements for Customers table
for index, row in customers_df.iterrows():
    print(f"INSERT INTO Customers (customerkey, gender, name, city, state_code, state, zip_code, country, continent, birthday) "
          f"VALUES ({row['customerkey']}, '{row['gender']}', '{row['name']}', '{row['city']}', '{row['state_code']}', "
          f"'{row['state']}', '{row['zip_code']}', '{row['country']}', '{row['continent']}', '{row['birthday']}');")



2. Exchange Rates Table

# Load the Exchange Rates dataset
exchange_rates_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Exchange_Rates.csv')

# Generate INSERT statements for Exchange Rates table
for index, row in exchange_rates_df.iterrows():
    print(f"INSERT INTO Exchange_Rates (date, currency_code, exchange_rate) "
          f"VALUES ('{row['date']}', '{row['currency_code']}', {row['exchange_rate']});")



3. Products Table

# Load the Products dataset
products_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Products.csv')

# Generate INSERT statements for Products table
for index, row in products_df.iterrows():
    print(f"INSERT INTO Products (ProductKey, ProductName, Brand, Color, UnitCostUSD, UnitPriceUSD, SubcategoryKey, Subcategory, CategoryKey, Category) "
          f"VALUES ({row['ProductKey']}, '{row['Product Name']}', '{row['Brand']}', '{row['Color']}', {row['Unit Cost USD']}, {row['Unit Price USD']}, "
          f"{row['SubcategoryKey']}, '{row['Subcategory']}', {row['CategoryKey']}, '{row['Category']}');")



4. Sales Table

import pandas as pd
import numpy as np

# Load the Sales dataset
sales_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Sales.csv')

# Generate INSERT statements for Sales table with ON DUPLICATE KEY UPDATE, and handle NaN as NULL
for index, row in sales_df.iterrows():
    order_number = row['Order Number']
    line_item = row['Line Item']
    order_date = f"'{row['Order Date']}'" if pd.notna(row['Order Date']) else 'NULL'
    delivery_date = f"'{row['Delivery Date']}'" if pd.notna(row['Delivery Date']) else 'NULL'
    customerkey = row['CustomerKey'] if pd.notna(row['CustomerKey']) else 'NULL'
    storekey = row['StoreKey'] if pd.notna(row['StoreKey']) else 'NULL'
    productkey = row['ProductKey'] if pd.notna(row['ProductKey']) else 'NULL'
    quantity = row['Quantity'] if pd.notna(row['Quantity']) else 'NULL'
    currency_code = f"'{row['Currency Code']}'" if pd.notna(row['Currency Code']) else 'NULL'

    print(f"INSERT INTO Sales (order_number, line_item, order_date, delivery_date, customerkey, storekey, productkey, quantity, currency_code) "
          f"VALUES ({order_number}, {line_item}, {order_date}, {delivery_date}, {customerkey}, {storekey}, {productkey}, {quantity}, {currency_code}) "
          f"ON DUPLICATE KEY UPDATE "
          f"order_date = VALUES(order_date), delivery_date = VALUES(delivery_date), customerkey = VALUES(customerkey), "
          f"storekey = VALUES(storekey), productkey = VALUES(productkey), quantity = VALUES(quantity), currency_code = VALUES(currency_code);")


5. Stores Table

import pandas as pd

# Load the Stores dataset
stores_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Cleaned_Stores.csv')

# Generate INSERT statements for Stores table with corrected date format and handle duplicates
for index, row in stores_df.iterrows():
    print(f"INSERT INTO Stores (storekey, country, state, square_meters, open_date) "
          f"VALUES ({row['StoreKey']}, '{row['Country']}', '{row['State']}', {row['Square Meters']}, '{row['Open Date']}') "
          f"ON DUPLICATE KEY UPDATE "
          f"country = VALUES(country), state = VALUES(state), square_meters = VALUES(square_meters), open_date = VALUES(open_date);")





6. Merged Table

# Load the Final Merged dataset
merged_df = pd.read_csv('C:/Users/lenovo/OneDrive/Desktop/Data_spark/final/Final_Merged.csv')

# Generate INSERT statements for the Merged table
# Generate INSERT statements for Merged table
for index, row in merged_df.iterrows():
    print(f"INSERT INTO Merged (OrderNumber, LineItem, OrderDate, DeliveryDate, CustomerKey, StoreKey, ProductKey, Quantity, CurrencyCode, "
          f"CustomerKey_2, Gender, CustomerName, City, StateCode, State, ZipCode, Country, Continent, Birthday, ProductName, Brand, Color, "
          f"UnitCostUSD, UnitPriceUSD, SubcategoryKey, Subcategory, CategoryKey, Category, StoreCountry, StoreState, SquareMeters, OpenDate, "
          f"Currency, ExchangeRate) "
          f"VALUES ({row['Order Number']}, {row['Line Item']}, '{row['Order Date']}', '{row['Delivery Date']}', {row['CustomerKey']}, {row['StoreKey']}, "
          f"{row['ProductKey']}, {row['Quantity']}, '{row['Currency Code']}', {row['customerkey']}, '{row['gender']}', '{row['name']}', '{row['city']}', "
          f"'{row['state_code']}', '{row['state']}', '{row['zip_code']}', '{row['country']}', '{row['continent']}', '{row['birthday']}', '{row['Product Name']}', "
          f"'{row['Brand']}', '{row['Color']}', {row['Unit Cost USD']}, {row['Unit Price USD']}, {row['SubcategoryKey']}, '{row['Subcategory']}', {row['CategoryKey']}, "
          f"'{row['Category']}', '{row['Country']}', '{row['State']}', {row['Square Meters']}, '{row['Open Date']}', '{row['currency']}', {row['exchange']});")
